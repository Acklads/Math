import os
import json
from datetime import datetime

class MathModelingProjectManager:
    """
    æ•°å­¦å»ºæ¨¡é¡¹ç›®ç®¡ç†å™¨
    ç”¨äºåˆ›å»ºå’Œç®¡ç†æ•°å­¦å»ºæ¨¡ç«èµ›é¡¹ç›®ç»“æ„
    """
    
    def __init__(self, project_root="."):
        self.project_root = project_root
        self.problems = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
        
    def create_problem_templates(self):
        """
        ä¸ºæ¯ä¸ªé—®é¢˜åˆ›å»ºä»£ç æ¨¡æ¿æ–‡ä»¶
        """
        print("ğŸ”§ æ­£åœ¨åˆ›å»ºé—®é¢˜ä»£ç æ¨¡æ¿...")
        
        for problem in self.problems:
            problem_path = os.path.join(self.project_root, problem)
            code_path = os.path.join(problem_path, "ä»£ç ")
            
            if os.path.exists(code_path):
                # åˆ›å»ºä¸»è¦ä»£ç æ–‡ä»¶
                self._create_main_code_file(code_path, problem)
                self._create_data_analysis_file(code_path, problem)
                self._create_visualization_file(code_path, problem)
                self._create_utils_file(code_path, problem)
                
                print(f"âœ“ {problem} æ¨¡æ¿æ–‡ä»¶åˆ›å»ºå®Œæˆ")
            else:
                print(f"âœ— {problem} æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
    
    def _create_main_code_file(self, code_path, problem):
        """
        åˆ›å»ºä¸»ä»£ç æ–‡ä»¶
        """
        filename = os.path.join(code_path, f"{problem}_ä¸»ç¨‹åº.py")
        
        content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
{problem} - ä¸»ç¨‹åº
æ•°å­¦å»ºæ¨¡ç«èµ›è§£å†³æ–¹æ¡ˆ

åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ä½œè€…: [è¯·å¡«å†™å›¢é˜Ÿä¿¡æ¯]
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class {problem.replace('é—®é¢˜', 'Problem')}Solver:
    """
    {problem}æ±‚è§£å™¨
    """
    
    def __init__(self):
        self.data = None
        self.model = None
        self.results = {{}}
        
    def load_data(self, data_path=None):
        """
        åŠ è½½æ•°æ®
        """
        try:
            if data_path:
                # æ ¹æ®æ–‡ä»¶ç±»å‹åŠ è½½æ•°æ®
                if data_path.endswith('.csv'):
                    self.data = pd.read_csv(data_path, encoding='utf-8')
                elif data_path.endswith('.xlsx'):
                    self.data = pd.read_excel(data_path)
                else:
                    print("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                    return False
                    
                print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {{self.data.shape}}")
                return True
            else:
                # ç”Ÿæˆç¤ºä¾‹æ•°æ®
                print("âš ï¸ æœªæŒ‡å®šæ•°æ®è·¯å¾„ï¼Œç”Ÿæˆç¤ºä¾‹æ•°æ®")
                self.data = self._generate_sample_data()
                return True
                
        except Exception as e:
            print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {{str(e)}}")
            return False
    
    def _generate_sample_data(self):
        """
        ç”Ÿæˆç¤ºä¾‹æ•°æ®
        """
        np.random.seed(42)
        n_samples = 100
        
        data = {{
            'x1': np.random.normal(0, 1, n_samples),
            'x2': np.random.normal(0, 1, n_samples),
            'x3': np.random.normal(0, 1, n_samples),
        }}
        
        # ç”Ÿæˆç›®æ ‡å˜é‡
        data['y'] = (2 * data['x1'] + 3 * data['x2'] + 
                    np.random.normal(0, 0.1, n_samples))
        
        return pd.DataFrame(data)
    
    def data_preprocessing(self):
        """
        æ•°æ®é¢„å¤„ç†
        """
        if self.data is None:
            print("âœ— è¯·å…ˆåŠ è½½æ•°æ®")
            return False
        
        print("ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_values = self.data.isnull().sum()
        if missing_values.any():
            print(f"å‘ç°ç¼ºå¤±å€¼:\n{{missing_values[missing_values > 0]}}")
            # å¤„ç†ç¼ºå¤±å€¼ï¼ˆè¿™é‡Œä½¿ç”¨å‡å€¼å¡«å……ï¼Œå®é™…åº”æ ¹æ®å…·ä½“æƒ…å†µè°ƒæ•´ï¼‰
            self.data = self.data.fillna(self.data.mean())
        
        # æ£€æŸ¥å¼‚å¸¸å€¼
        numeric_columns = self.data.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            Q1 = self.data[col].quantile(0.25)
            Q3 = self.data[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = ((self.data[col] < (Q1 - 1.5 * IQR)) | 
                       (self.data[col] > (Q3 + 1.5 * IQR))).sum()
            if outliers > 0:
                print(f"{{col}} åˆ—å‘ç° {{outliers}} ä¸ªå¼‚å¸¸å€¼")
        
        print("âœ“ æ•°æ®é¢„å¤„ç†å®Œæˆ")
        return True
    
    def solve(self):
        """
        æ±‚è§£ä¸»å‡½æ•°
        """
        print(f"ğŸ¯ å¼€å§‹æ±‚è§£{problem}...")
        
        # TODO: åœ¨è¿™é‡Œå®ç°å…·ä½“çš„æ±‚è§£ç®—æ³•
        # ç¤ºä¾‹ï¼šç®€å•çš„çº¿æ€§å›å½’
        if self.data is not None and 'y' in self.data.columns:
            X = self.data.drop('y', axis=1)
            y = self.data['y']
            
            # åˆ†å‰²æ•°æ®
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # ç®€å•çš„çº¿æ€§å›å½’ç¤ºä¾‹
            from sklearn.linear_model import LinearRegression
            self.model = LinearRegression()
            self.model.fit(X_train, y_train)
            
            # é¢„æµ‹
            y_pred = self.model.predict(X_test)
            
            # è¯„ä¼°
            mse = mean_squared_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            self.results = {{
                'mse': mse,
                'r2': r2,
                'coefficients': self.model.coef_.tolist(),
                'intercept': self.model.intercept_
            }}
            
            print(f"âœ“ æ±‚è§£å®Œæˆ")
            print(f"  å‡æ–¹è¯¯å·® (MSE): {{mse:.4f}}")
            print(f"  å†³å®šç³»æ•° (RÂ²): {{r2:.4f}}")
            
            return True
        else:
            print("âœ— æ•°æ®æ ¼å¼ä¸æ­£ç¡®æˆ–ç¼ºå°‘ç›®æ ‡å˜é‡")
            return False
    
    def save_results(self, output_dir="../å¯è§†åŒ–ç»“æœ"):
        """
        ä¿å­˜ç»“æœ
        """
        if not self.results:
            print("âœ— æ²¡æœ‰ç»“æœå¯ä¿å­˜")
            return False
        
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            result_file = os.path.join(output_dir, f"{problem}_ç»“æœ.json")
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {{result_file}}")
            return True
            
        except Exception as e:
            print(f"âœ— ä¿å­˜ç»“æœå¤±è´¥: {{str(e)}}")
            return False

def main():
    """
    ä¸»å‡½æ•°
    """
    print(f"ğŸš€ {problem} æ±‚è§£ç¨‹åºå¯åŠ¨")
    print("=" * 50)
    
    # åˆ›å»ºæ±‚è§£å™¨
    solver = {problem.replace('é—®é¢˜', 'Problem')}Solver()
    
    # æ‰§è¡Œæ±‚è§£æµç¨‹
    if solver.load_data():
        if solver.data_preprocessing():
            if solver.solve():
                solver.save_results()
                print(f"\nğŸ‰ {problem} æ±‚è§£å®Œæˆï¼")
            else:
                print(f"\nâŒ {problem} æ±‚è§£å¤±è´¥")
        else:
            print(f"\nâŒ æ•°æ®é¢„å¤„ç†å¤±è´¥")
    else:
        print(f"\nâŒ æ•°æ®åŠ è½½å¤±è´¥")

if __name__ == "__main__":
    main()
'''
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _create_data_analysis_file(self, code_path, problem):
        """
        åˆ›å»ºæ•°æ®åˆ†ææ–‡ä»¶
        """
        filename = os.path.join(code_path, f"{problem}_æ•°æ®åˆ†æ.py")
        
        content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
{problem} - æ•°æ®åˆ†ææ¨¡å—
ç”¨äºæ•°æ®æ¢ç´¢æ€§åˆ†æå’Œç»Ÿè®¡æè¿°

åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class DataAnalyzer:
    """
    æ•°æ®åˆ†æå™¨
    """
    
    def __init__(self, data):
        self.data = data
        self.analysis_results = {{}}
    
    def basic_info(self):
        """
        åŸºæœ¬ä¿¡æ¯åˆ†æ
        """
        print("ğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯")
        print("=" * 30)
        print(f"æ•°æ®å½¢çŠ¶: {{self.data.shape}}")
        print(f"æ•°æ®ç±»å‹:\n{{self.data.dtypes}}")
        print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:\n{{self.data.isnull().sum()}}")
        
        # æ•°å€¼å‹å˜é‡æè¿°æ€§ç»Ÿè®¡
        numeric_data = self.data.select_dtypes(include=[np.number])
        if not numeric_data.empty:
            print(f"\nğŸ“ˆ æè¿°æ€§ç»Ÿè®¡:")
            print(numeric_data.describe())
    
    def correlation_analysis(self):
        """
        ç›¸å…³æ€§åˆ†æ
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        if numeric_data.shape[1] < 2:
            print("æ•°å€¼å‹å˜é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")
            return
        
        # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
        corr_matrix = numeric_data.corr()
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5)
        plt.title(f'{problem} - å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾')
        plt.tight_layout()
        plt.savefig(f'../å¯è§†åŒ–ç»“æœ/{problem}_ç›¸å…³æ€§åˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return corr_matrix
    
    def distribution_analysis(self):
        """
        åˆ†å¸ƒåˆ†æ
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        
        if numeric_data.empty:
            print("æ²¡æœ‰æ•°å€¼å‹å˜é‡å¯åˆ†æ")
            return
        
        n_cols = min(3, len(numeric_data.columns))
        n_rows = (len(numeric_data.columns) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
        if n_rows == 1:
            axes = [axes] if n_cols == 1 else axes
        else:
            axes = axes.flatten()
        
        for i, col in enumerate(numeric_data.columns):
            if i < len(axes):
                # ç›´æ–¹å›¾
                axes[i].hist(numeric_data[col], bins=30, alpha=0.7, edgecolor='black')
                axes[i].set_title(f'{{col}} åˆ†å¸ƒ')
                axes[i].set_xlabel(col)
                axes[i].set_ylabel('é¢‘æ•°')
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                mean_val = numeric_data[col].mean()
                std_val = numeric_data[col].std()
                axes[i].axvline(mean_val, color='red', linestyle='--', 
                              label=f'å‡å€¼: {{mean_val:.2f}}')
                axes[i].legend()
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(numeric_data.columns), len(axes)):
            axes[i].set_visible(False)
        
        plt.suptitle(f'{problem} - å˜é‡åˆ†å¸ƒåˆ†æ')
        plt.tight_layout()
        plt.savefig(f'../å¯è§†åŒ–ç»“æœ/{problem}_åˆ†å¸ƒåˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def outlier_detection(self):
        """
        å¼‚å¸¸å€¼æ£€æµ‹
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        
        if numeric_data.empty:
            return
        
        outliers_info = {{}}
        
        for col in numeric_data.columns:
            Q1 = numeric_data[col].quantile(0.25)
            Q3 = numeric_data[col].quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = numeric_data[(numeric_data[col] < lower_bound) | 
                                  (numeric_data[col] > upper_bound)][col]
            
            outliers_info[col] = {{
                'count': len(outliers),
                'percentage': len(outliers) / len(numeric_data) * 100,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound
            }}
        
        # ç»˜åˆ¶ç®±çº¿å›¾
        plt.figure(figsize=(12, 6))
        numeric_data.boxplot()
        plt.title(f'{problem} - å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆç®±çº¿å›¾ï¼‰')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(f'../å¯è§†åŒ–ç»“æœ/{problem}_å¼‚å¸¸å€¼æ£€æµ‹.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return outliers_info

def main():
    """
    æ•°æ®åˆ†æä¸»å‡½æ•°
    """
    print(f"ğŸ“Š {problem} æ•°æ®åˆ†ææ¨¡å—")
    print("=" * 40)
    
    # è¿™é‡Œéœ€è¦åŠ è½½æ•°æ®
    # data = pd.read_csv('your_data.csv')  # æ›¿æ¢ä¸ºå®é™…æ•°æ®è·¯å¾„
    
    # ç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    data = pd.DataFrame({{
        'feature1': np.random.normal(100, 15, 1000),
        'feature2': np.random.exponential(2, 1000),
        'feature3': np.random.uniform(0, 100, 1000),
        'target': np.random.normal(50, 10, 1000)
    }})
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DataAnalyzer(data)
    
    # æ‰§è¡Œåˆ†æ
    analyzer.basic_info()
    print("\n" + "="*50 + "\n")
    
    corr_matrix = analyzer.correlation_analysis()
    print("\n" + "="*50 + "\n")
    
    analyzer.distribution_analysis()
    print("\n" + "="*50 + "\n")
    
    outliers_info = analyzer.outlier_detection()
    
    print("\nğŸ‰ æ•°æ®åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
'''
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _create_visualization_file(self, code_path, problem):
        """
        åˆ›å»ºå¯è§†åŒ–æ–‡ä»¶
        """
        filename = os.path.join(code_path, f"{problem}_å¯è§†åŒ–.py")
        
        content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
{problem} - å¯è§†åŒ–æ¨¡å—
ç”¨äºç”Ÿæˆå„ç§å›¾è¡¨å’Œå¯è§†åŒ–ç»“æœ

åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®æ ·å¼
sns.set_style("whitegrid")
plt.style.use('seaborn-v0_8')

class Visualizer:
    """
    å¯è§†åŒ–å™¨
    """
    
    def __init__(self, data, results=None):
        self.data = data
        self.results = results
        self.output_dir = "../å¯è§†åŒ–ç»“æœ"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        import os
        os.makedirs(self.output_dir, exist_ok=True)
    
    def plot_data_overview(self):
        """
        æ•°æ®æ¦‚è§ˆå›¾
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        
        if numeric_data.empty:
            print("æ²¡æœ‰æ•°å€¼å‹æ•°æ®å¯å¯è§†åŒ–")
            return
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. æ•°æ®åˆ†å¸ƒæ¦‚è§ˆ
        numeric_data.hist(bins=30, ax=axes[0,0], alpha=0.7)
        axes[0,0].set_title('æ•°æ®åˆ†å¸ƒæ¦‚è§ˆ')
        
        # 2. ç›¸å…³æ€§çƒ­åŠ›å›¾
        if numeric_data.shape[1] > 1:
            corr = numeric_data.corr()
            sns.heatmap(corr, annot=True, cmap='coolwarm', ax=axes[0,1])
            axes[0,1].set_title('ç›¸å…³æ€§çŸ©é˜µ')
        
        # 3. ç®±çº¿å›¾
        numeric_data.boxplot(ax=axes[1,0])
        axes[1,0].set_title('å¼‚å¸¸å€¼æ£€æµ‹')
        axes[1,0].tick_params(axis='x', rotation=45)
        
        # 4. æ•£ç‚¹å›¾çŸ©é˜µï¼ˆå¦‚æœå˜é‡ä¸å¤šï¼‰
        if numeric_data.shape[1] <= 4:
            pd.plotting.scatter_matrix(numeric_data, ax=axes[1,1], alpha=0.6)
            axes[1,1].set_title('æ•£ç‚¹å›¾çŸ©é˜µ')
        else:
            # é€‰æ‹©å‰ä¸¤ä¸ªå˜é‡ç»˜åˆ¶æ•£ç‚¹å›¾
            cols = numeric_data.columns[:2]
            axes[1,1].scatter(numeric_data[cols[0]], numeric_data[cols[1]], alpha=0.6)
            axes[1,1].set_xlabel(cols[0])
            axes[1,1].set_ylabel(cols[1])
            axes[1,1].set_title(f'{{cols[0]}} vs {{cols[1]}}')
        
        plt.suptitle(f'{problem} - æ•°æ®æ¦‚è§ˆ', fontsize=16)
        plt.tight_layout()
        plt.savefig(f'{{self.output_dir}}/{problem}_æ•°æ®æ¦‚è§ˆ.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_results(self):
        """
        ç»“æœå¯è§†åŒ–
        """
        if not self.results:
            print("æ²¡æœ‰ç»“æœæ•°æ®å¯å¯è§†åŒ–")
            return
        
        # æ ¹æ®ç»“æœç±»å‹åˆ›å»ºä¸åŒçš„å›¾è¡¨
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # ç¤ºä¾‹ï¼šå¦‚æœæœ‰é¢„æµ‹ç»“æœ
        if 'predictions' in self.results:
            # å®é™…å€¼ vs é¢„æµ‹å€¼
            actual = self.results.get('actual', [])
            predicted = self.results.get('predictions', [])
            
            if actual and predicted:
                axes[0].scatter(actual, predicted, alpha=0.6)
                axes[0].plot([min(actual), max(actual)], 
                           [min(actual), max(actual)], 'r--', lw=2)
                axes[0].set_xlabel('å®é™…å€¼')
                axes[0].set_ylabel('é¢„æµ‹å€¼')
                axes[0].set_title('å®é™…å€¼ vs é¢„æµ‹å€¼')
                
                # æ®‹å·®å›¾
                residuals = np.array(actual) - np.array(predicted)
                axes[1].scatter(predicted, residuals, alpha=0.6)
                axes[1].axhline(y=0, color='r', linestyle='--')
                axes[1].set_xlabel('é¢„æµ‹å€¼')
                axes[1].set_ylabel('æ®‹å·®')
                axes[1].set_title('æ®‹å·®å›¾')
        
        # å¦‚æœæœ‰å…¶ä»–ç±»å‹çš„ç»“æœï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        
        plt.suptitle(f'{problem} - ç»“æœå¯è§†åŒ–')
        plt.tight_layout()
        plt.savefig(f'{{self.output_dir}}/{problem}_ç»“æœå¯è§†åŒ–.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_interactive_plot(self):
        """
        åˆ›å»ºäº¤äº’å¼å›¾è¡¨
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        
        if numeric_data.shape[1] < 2:
            print("æ•°æ®ç»´åº¦ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºäº¤äº’å¼å›¾è¡¨")
            return
        
        # åˆ›å»ºäº¤äº’å¼æ•£ç‚¹å›¾
        fig = px.scatter_matrix(
            numeric_data,
            title=f'{problem} - äº¤äº’å¼æ•£ç‚¹å›¾çŸ©é˜µ',
            height=600
        )
        
        # ä¿å­˜ä¸ºHTMLæ–‡ä»¶
        fig.write_html(f'{{self.output_dir}}/{problem}_äº¤äº’å¼å›¾è¡¨.html')
        fig.show()
    
    def plot_model_performance(self, metrics):
        """
        æ¨¡å‹æ€§èƒ½å¯è§†åŒ–
        """
        if not metrics:
            return
        
        # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡å›¾è¡¨
        fig, ax = plt.subplots(figsize=(10, 6))
        
        metric_names = list(metrics.keys())
        metric_values = list(metrics.values())
        
        bars = ax.bar(metric_names, metric_values, 
                     color=['skyblue', 'lightgreen', 'lightcoral', 'gold'])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, metric_values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{{value:.4f}}', ha='center', va='bottom')
        
        ax.set_title(f'{problem} - æ¨¡å‹æ€§èƒ½æŒ‡æ ‡')
        ax.set_ylabel('æŒ‡æ ‡å€¼')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(f'{{self.output_dir}}/{problem}_æ¨¡å‹æ€§èƒ½.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_report_plots(self):
        """
        ç”ŸæˆæŠ¥å‘Šç”¨å›¾è¡¨
        """
        print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆ{problem}å¯è§†åŒ–æŠ¥å‘Š...")
        
        # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        self.plot_data_overview()
        
        if self.results:
            self.plot_results()
            
            # å¦‚æœæœ‰æ€§èƒ½æŒ‡æ ‡
            if 'metrics' in self.results:
                self.plot_model_performance(self.results['metrics'])
        
        # ç”Ÿæˆäº¤äº’å¼å›¾è¡¨
        try:
            self.create_interactive_plot()
        except Exception as e:
            print(f"äº¤äº’å¼å›¾è¡¨ç”Ÿæˆå¤±è´¥: {{e}}")
        
        print(f"âœ“ {problem}å¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        print(f"ğŸ“ å›¾è¡¨ä¿å­˜ä½ç½®: {{self.output_dir}}")

def main():
    """
    å¯è§†åŒ–ä¸»å‡½æ•°
    """
    print(f"ğŸ¨ {problem} å¯è§†åŒ–æ¨¡å—")
    print("=" * 40)
    
    # ç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    data = pd.DataFrame({{
        'feature1': np.random.normal(100, 15, 200),
        'feature2': np.random.exponential(2, 200),
        'feature3': np.random.uniform(0, 100, 200),
        'target': np.random.normal(50, 10, 200)
    }})
    
    # ç¤ºä¾‹ç»“æœ
    results = {{
        'metrics': {{
            'MSE': 0.1234,
            'RÂ²': 0.8765,
            'MAE': 0.0987
        }}
    }}
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = Visualizer(data, results)
    
    # ç”ŸæˆæŠ¥å‘Šå›¾è¡¨
    visualizer.generate_report_plots()
    
    print("\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")

if __name__ == "__main__":
    main()
'''
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _create_utils_file(self, code_path, problem):
        """
        åˆ›å»ºå·¥å…·å‡½æ•°æ–‡ä»¶
        """
        filename = os.path.join(code_path, f"{problem}_å·¥å…·å‡½æ•°.py")
        
        content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
{problem} - å·¥å…·å‡½æ•°æ¨¡å—
åŒ…å«å¸¸ç”¨çš„å·¥å…·å‡½æ•°å’Œè¾…åŠ©æ–¹æ³•

åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

import numpy as np
import pandas as pd
import json
import pickle
from datetime import datetime
import os

def save_model(model, filename):
    """
    ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶
    
    Args:
        model: è¦ä¿å­˜çš„æ¨¡å‹
        filename: æ–‡ä»¶å
    """
    try:
        with open(filename, 'wb') as f:
            pickle.dump(model, f)
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {{filename}}")
        return True
    except Exception as e:
        print(f"âœ— æ¨¡å‹ä¿å­˜å¤±è´¥: {{str(e)}}")
        return False

def load_model(filename):
    """
    ä»æ–‡ä»¶åŠ è½½æ¨¡å‹
    
    Args:
        filename: æ¨¡å‹æ–‡ä»¶å
    
    Returns:
        åŠ è½½çš„æ¨¡å‹
    """
    try:
        with open(filename, 'rb') as f:
            model = pickle.load(f)
        print(f"âœ“ æ¨¡å‹å·²ä» {{filename}} åŠ è½½")
        return model
    except Exception as e:
        print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {{str(e)}}")
        return None

def save_results_to_json(results, filename):
    """
    å°†ç»“æœä¿å­˜ä¸ºJSONæ–‡ä»¶
    
    Args:
        results: ç»“æœå­—å…¸
        filename: æ–‡ä»¶å
    """
    try:
        # å¤„ç†numpyæ•°ç»„
        def convert_numpy(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {{k: convert_numpy(v) for k, v in obj.items()}}
            elif isinstance(obj, list):
                return [convert_numpy(item) for item in obj]
            return obj
        
        converted_results = convert_numpy(results)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(converted_results, f, ensure_ascii=False, indent=2)
        print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {{filename}}")
        return True
    except Exception as e:
        print(f"âœ— ç»“æœä¿å­˜å¤±è´¥: {{str(e)}}")
        return False

def load_data_smart(file_path):
    """
    æ™ºèƒ½åŠ è½½æ•°æ®æ–‡ä»¶
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        pandas DataFrame
    """
    try:
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.csv':
            # å°è¯•ä¸åŒçš„ç¼–ç 
            for encoding in ['utf-8', 'gbk', 'gb2312']:
                try:
                    return pd.read_csv(file_path, encoding=encoding)
                except UnicodeDecodeError:
                    continue
            raise ValueError("æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ")
            
        elif file_ext in ['.xlsx', '.xls']:
            return pd.read_excel(file_path)
            
        elif file_ext == '.json':
            return pd.read_json(file_path)
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {{file_ext}}")
            
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {{str(e)}}")
        return None

def calculate_metrics(y_true, y_pred, problem_type='regression'):
    """
    è®¡ç®—æ¨¡å‹è¯„ä¼°æŒ‡æ ‡
    
    Args:
        y_true: çœŸå®å€¼
        y_pred: é¢„æµ‹å€¼
        problem_type: é—®é¢˜ç±»å‹ ('regression' æˆ– 'classification')
    
    Returns:
        æŒ‡æ ‡å­—å…¸
    """
    metrics = {{}}
    
    if problem_type == 'regression':
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        metrics['MSE'] = mean_squared_error(y_true, y_pred)
        metrics['RMSE'] = np.sqrt(metrics['MSE'])
        metrics['MAE'] = mean_absolute_error(y_true, y_pred)
        metrics['R2'] = r2_score(y_true, y_pred)
        
    elif problem_type == 'classification':
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        
        metrics['Accuracy'] = accuracy_score(y_true, y_pred)
        metrics['Precision'] = precision_score(y_true, y_pred, average='weighted')
        metrics['Recall'] = recall_score(y_true, y_pred, average='weighted')
        metrics['F1'] = f1_score(y_true, y_pred, average='weighted')
    
    return metrics

def normalize_data(data, method='minmax'):
    """
    æ•°æ®æ ‡å‡†åŒ–
    
    Args:
        data: è¦æ ‡å‡†åŒ–çš„æ•°æ®
        method: æ ‡å‡†åŒ–æ–¹æ³• ('minmax', 'zscore')
    
    Returns:
        æ ‡å‡†åŒ–åçš„æ•°æ®å’Œæ ‡å‡†åŒ–å™¨
    """
    if method == 'minmax':
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
    elif method == 'zscore':
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ‡å‡†åŒ–æ–¹æ³•: {{method}}")
    
    if isinstance(data, pd.DataFrame):
        scaled_data = pd.DataFrame(
            scaler.fit_transform(data),
            columns=data.columns,
            index=data.index
        )
    else:
        scaled_data = scaler.fit_transform(data)
    
    return scaled_data, scaler

def create_time_features(df, date_column):
    """
    ä»æ—¥æœŸåˆ—åˆ›å»ºæ—¶é—´ç‰¹å¾
    
    Args:
        df: æ•°æ®æ¡†
        date_column: æ—¥æœŸåˆ—å
    
    Returns:
        æ·»åŠ æ—¶é—´ç‰¹å¾åçš„æ•°æ®æ¡†
    """
    df = df.copy()
    df[date_column] = pd.to_datetime(df[date_column])
    
    df['year'] = df[date_column].dt.year
    df['month'] = df[date_column].dt.month
    df['day'] = df[date_column].dt.day
    df['dayofweek'] = df[date_column].dt.dayofweek
    df['quarter'] = df[date_column].dt.quarter
    df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)
    
    return df

def log_experiment(experiment_name, parameters, results, log_file="experiment_log.json"):
    """
    è®°å½•å®éªŒæ—¥å¿—
    
    Args:
        experiment_name: å®éªŒåç§°
        parameters: å®éªŒå‚æ•°
        results: å®éªŒç»“æœ
        log_file: æ—¥å¿—æ–‡ä»¶å
    """
    log_entry = {{
        'timestamp': datetime.now().isoformat(),
        'experiment_name': experiment_name,
        'parameters': parameters,
        'results': results
    }}
    
    # è¯»å–ç°æœ‰æ—¥å¿—
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
        except:
            logs = []
    else:
        logs = []
    
    # æ·»åŠ æ–°æ—¥å¿—
    logs.append(log_entry)
    
    # ä¿å­˜æ—¥å¿—
    try:
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(logs, f, ensure_ascii=False, indent=2)
        print(f"âœ“ å®éªŒæ—¥å¿—å·²è®°å½•åˆ°: {{log_file}}")
    except Exception as e:
        print(f"âœ— æ—¥å¿—è®°å½•å¤±è´¥: {{str(e)}}")

def print_progress_bar(iteration, total, prefix='', suffix='', length=50, fill='â–ˆ'):
    """
    æ‰“å°è¿›åº¦æ¡
    
    Args:
        iteration: å½“å‰è¿­ä»£æ¬¡æ•°
        total: æ€»è¿­ä»£æ¬¡æ•°
        prefix: å‰ç¼€å­—ç¬¦ä¸²
        suffix: åç¼€å­—ç¬¦ä¸²
        length: è¿›åº¦æ¡é•¿åº¦
        fill: å¡«å……å­—ç¬¦
    """
    percent = ("{{0:.1f}}").format(100 * (iteration / float(total)))
    filled_length = int(length * iteration // total)
    bar = fill * filled_length + '-' * (length - filled_length)
    print(f'\r{{prefix}} |{{bar}}| {{percent}}% {{suffix}}', end='\r')
    
    if iteration == total:
        print()

class Timer:
    """
    è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    """
    
    def __init__(self, description="æ“ä½œ"):
        self.description = description
        self.start_time = None
    
    def __enter__(self):
        self.start_time = datetime.now()
        print(f"â±ï¸ å¼€å§‹{{self.description}}...")
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        end_time = datetime.now()
        duration = end_time - self.start_time
        print(f"âœ“ {{self.description}}å®Œæˆï¼Œè€—æ—¶: {{duration.total_seconds():.2f}}ç§’")

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    print(f"ğŸ”§ {problem} å·¥å…·å‡½æ•°æ¨¡å—")
    print("=" * 40)
    
    # ç¤ºä¾‹ï¼šä½¿ç”¨è®¡æ—¶å™¨
    with Timer("æ•°æ®å¤„ç†"):
        import time
        time.sleep(1)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    
    print("\nğŸ‰ å·¥å…·å‡½æ•°æ¨¡å—æµ‹è¯•å®Œæˆï¼")
'''
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def create_readme_files(self):
        """
        ä¸ºæ¯ä¸ªé—®é¢˜æ–‡ä»¶å¤¹åˆ›å»ºREADMEæ–‡ä»¶
        """
        print("ğŸ“ æ­£åœ¨åˆ›å»ºREADMEæ–‡ä»¶...")
        
        for problem in self.problems:
            readme_path = os.path.join(self.project_root, problem, "README.md")
            
            content = f'''# {problem}

## é—®é¢˜æè¿°
è¯·åœ¨æ­¤å¤„å¡«å†™{problem}çš„å…·ä½“æè¿°å’Œè¦æ±‚ã€‚

## è§£å†³æ€è·¯
1. æ•°æ®åˆ†æå’Œé¢„å¤„ç†
2. æ¨¡å‹å»ºç«‹
3. æ±‚è§£å’Œä¼˜åŒ–
4. ç»“æœéªŒè¯å’Œå¯è§†åŒ–

## æ–‡ä»¶ç»“æ„
```
{problem}/
â”œâ”€â”€ ä»£ç /
â”‚   â”œâ”€â”€ {problem}_ä¸»ç¨‹åº.py          # ä¸»è¦æ±‚è§£ç¨‹åº
â”‚   â”œâ”€â”€ {problem}_æ•°æ®åˆ†æ.py        # æ•°æ®åˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ {problem}_å¯è§†åŒ–.py          # å¯è§†åŒ–æ¨¡å—
â”‚   â””â”€â”€ {problem}_å·¥å…·å‡½æ•°.py        # å·¥å…·å‡½æ•°æ¨¡å—
â”œâ”€â”€ å¯è§†åŒ–ç»“æœ/                      # å›¾è¡¨å’Œç»“æœæ–‡ä»¶
â””â”€â”€ README.md                        # æœ¬æ–‡ä»¶
```

## ä½¿ç”¨è¯´æ˜
1. é¦–å…ˆè¿è¡Œæ•°æ®åˆ†ææ¨¡å—ï¼Œäº†è§£æ•°æ®ç‰¹å¾
2. æ ¹æ®åˆ†æç»“æœè°ƒæ•´ä¸»ç¨‹åºä¸­çš„ç®—æ³•
3. è¿è¡Œä¸»ç¨‹åºè¿›è¡Œæ±‚è§£
4. ä½¿ç”¨å¯è§†åŒ–æ¨¡å—ç”Ÿæˆå›¾è¡¨

## ä¾èµ–åº“
- numpy
- pandas
- matplotlib
- seaborn
- scikit-learn
- plotly (å¯é€‰ï¼Œç”¨äºäº¤äº’å¼å›¾è¡¨)

## æ³¨æ„äº‹é¡¹
- è¯·æ ¹æ®å®é™…é¢˜ç›®è¦æ±‚è°ƒæ•´ä»£ç 
- ç¡®ä¿æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡®
- è¿è¡Œå‰æ£€æŸ¥æ‰€éœ€åº“æ˜¯å¦å·²å®‰è£…

## æ›´æ–°æ—¥å¿—
- {datetime.now().strftime('%Y-%m-%d')}: åˆ›å»ºé¡¹ç›®ç»“æ„
'''
            
            try:
                with open(readme_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ“ {problem}/README.md åˆ›å»ºå®Œæˆ")
            except Exception as e:
                print(f"âœ— {problem}/README.md åˆ›å»ºå¤±è´¥: {str(e)}")
    
    def create_main_readme(self):
        """
        åˆ›å»ºé¡¹ç›®ä¸»READMEæ–‡ä»¶
        """
        readme_path = os.path.join(self.project_root, "README.md")
        
        content = f'''# æ•°å­¦å»ºæ¨¡ç«èµ›é¡¹ç›®

## é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®ä¸ºå…¨å›½æ•°å­¦å»ºæ¨¡ç«èµ›å‡†å¤‡çš„æ ‡å‡†åŒ–é¡¹ç›®ç»“æ„ï¼ŒåŒ…å«å®Œæ•´çš„ä»£ç æ¨¡æ¿å’Œå·¥å…·ã€‚

## é¡¹ç›®ç»“æ„
```
Math_test_project/
â”œâ”€â”€ é—®é¢˜1/
â”‚   â”œâ”€â”€ ä»£ç /
â”‚   â”‚   â”œâ”€â”€ é—®é¢˜1_ä¸»ç¨‹åº.py
â”‚   â”‚   â”œâ”€â”€ é—®é¢˜1_æ•°æ®åˆ†æ.py
â”‚   â”‚   â”œâ”€â”€ é—®é¢˜1_å¯è§†åŒ–.py
â”‚   â”‚   â””â”€â”€ é—®é¢˜1_å·¥å…·å‡½æ•°.py
â”‚   â”œâ”€â”€ å¯è§†åŒ–ç»“æœ/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ é—®é¢˜2/
â”‚   â”œâ”€â”€ ä»£ç /
â”‚   â”œâ”€â”€ å¯è§†åŒ–ç»“æœ/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ é—®é¢˜3/
â”‚   â”œâ”€â”€ ä»£ç /
â”‚   â”œâ”€â”€ å¯è§†åŒ–ç»“æœ/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ é¢˜ç›®åˆ†æå™¨.py                    # Wordæ–‡æ¡£é¢˜ç›®åˆ†æå·¥å…·
â”œâ”€â”€ é¡¹ç›®ç®¡ç†å™¨.py                    # é¡¹ç›®ç®¡ç†å·¥å…·
â”œâ”€â”€ read_docx.py                     # Wordæ–‡æ¡£è¯»å–å·¥å…·
â””â”€â”€ README.md                        # æœ¬æ–‡ä»¶
```

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…å¿…è¦çš„Pythonåº“
python -m pip install numpy pandas matplotlib seaborn scikit-learn python-docx plotly
```

### 2. é¢˜ç›®åˆ†æ
```bash
# å°†æ¯”èµ›é¢˜ç›®Wordæ–‡æ¡£æ”¾å…¥é¡¹ç›®æ ¹ç›®å½•
# è¿è¡Œé¢˜ç›®åˆ†æå™¨
python é¢˜ç›®åˆ†æå™¨.py
```

### 3. å¼€å§‹è§£é¢˜
1. æŸ¥çœ‹ç”Ÿæˆçš„é¢˜ç›®åˆ†ææŠ¥å‘Š
2. è¿›å…¥å¯¹åº”é—®é¢˜æ–‡ä»¶å¤¹
3. æ ¹æ®é¢˜ç›®è¦æ±‚ä¿®æ”¹ä»£ç æ¨¡æ¿
4. è¿è¡Œæ±‚è§£ç¨‹åº

## å·¥å…·è¯´æ˜

### é¢˜ç›®åˆ†æå™¨ (é¢˜ç›®åˆ†æå™¨.py)
- è‡ªåŠ¨è¯»å–Wordæ ¼å¼çš„æ¯”èµ›é¢˜ç›®
- è¯†åˆ«é—®é¢˜ç»“æ„å’Œå…³é”®è¯
- ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œè§£é¢˜å»ºè®®
- è¾“å‡ºJSONæ ¼å¼çš„åˆ†æç»“æœ

### é¡¹ç›®ç®¡ç†å™¨ (é¡¹ç›®ç®¡ç†å™¨.py)
- åˆ›å»ºæ ‡å‡†åŒ–çš„é¡¹ç›®ç»“æ„
- ç”Ÿæˆä»£ç æ¨¡æ¿æ–‡ä»¶
- ç®¡ç†é¡¹ç›®æ–‡ä»¶å’Œç›®å½•

### ä»£ç æ¨¡æ¿ç‰¹æ€§
- **ä¸»ç¨‹åº**: å®Œæ•´çš„æ±‚è§£æµç¨‹æ¡†æ¶
- **æ•°æ®åˆ†æ**: æ•°æ®æ¢ç´¢å’Œé¢„å¤„ç†å·¥å…·
- **å¯è§†åŒ–**: å›¾è¡¨ç”Ÿæˆå’Œç»“æœå±•ç¤º
- **å·¥å…·å‡½æ•°**: å¸¸ç”¨çš„è¾…åŠ©å‡½æ•°

## ä½¿ç”¨å»ºè®®

### æ¯”èµ›æµç¨‹
1. **é¢˜ç›®ç†è§£** (30åˆ†é’Ÿ)
   - ä½¿ç”¨é¢˜ç›®åˆ†æå™¨å¿«é€Ÿç†è§£é¢˜ç›®
   - è¯†åˆ«å…³é”®é—®é¢˜å’Œçº¦æŸæ¡ä»¶
   
2. **æ•°æ®åˆ†æ** (1-2å°æ—¶)
   - è¿è¡Œæ•°æ®åˆ†ææ¨¡å—
   - ç†è§£æ•°æ®ç‰¹å¾å’Œåˆ†å¸ƒ
   
3. **æ¨¡å‹å»ºç«‹** (4-6å°æ—¶)
   - æ ¹æ®é—®é¢˜ç‰¹ç‚¹é€‰æ‹©åˆé€‚ç®—æ³•
   - ä¿®æ”¹ä¸»ç¨‹åºæ¨¡æ¿
   
4. **æ±‚è§£ä¼˜åŒ–** (2-4å°æ—¶)
   - è°ƒè¯•å’Œä¼˜åŒ–ç®—æ³•
   - éªŒè¯ç»“æœåˆç†æ€§
   
5. **ç»“æœå±•ç¤º** (1-2å°æ—¶)
   - ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
   - æ•´ç†æœ€ç»ˆç»“æœ

### å›¢é˜Ÿåä½œ
- æ¯ä¸ªæˆå‘˜è´Ÿè´£ä¸€ä¸ªé—®é¢˜æ–‡ä»¶å¤¹
- ä½¿ç”¨ç»Ÿä¸€çš„ä»£ç é£æ ¼å’Œæ³¨é‡Š
- å®šæœŸåŒæ­¥è¿›åº¦å’Œç»“æœ

## å¸¸ç”¨ç®—æ³•åº“

### ä¼˜åŒ–ç®—æ³•
- scipy.optimize: æ•°å­¦ä¼˜åŒ–
- cvxpy: å‡¸ä¼˜åŒ–
- pulp: çº¿æ€§è§„åˆ’

### æœºå™¨å­¦ä¹ 
- scikit-learn: ç»å…¸æœºå™¨å­¦ä¹ 
- tensorflow/pytorch: æ·±åº¦å­¦ä¹ 
- xgboost: æ¢¯åº¦æå‡

### æ•°å€¼è®¡ç®—
- numpy: æ•°å€¼è®¡ç®—åŸºç¡€
- scipy: ç§‘å­¦è®¡ç®—
- sympy: ç¬¦å·è®¡ç®—

## æ³¨æ„äº‹é¡¹
- ç¡®ä¿æ‰€æœ‰ä»£ç éƒ½æœ‰ä¸­æ–‡æ³¨é‡Š
- ä¿å­˜å¥½ä¸­é—´ç»“æœå’Œæ¨¡å‹æ–‡ä»¶
- åŠæ—¶å¤‡ä»½é‡è¦ä»£ç å’Œæ•°æ®
- æ³¨æ„æ—¶é—´ç®¡ç†ï¼Œåˆç†åˆ†é…å„é—®é¢˜æ—¶é—´

## æ›´æ–°æ—¥å¿—
- {datetime.now().strftime('%Y-%m-%d')}: åˆ›å»ºé¡¹ç›®ç»“æ„å’Œæ¨¡æ¿

---

**ç¥æ¯”èµ›é¡ºåˆ©ï¼ğŸ†**
'''
        
        try:
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print("âœ“ ä¸»README.md åˆ›å»ºå®Œæˆ")
        except Exception as e:
            print(f"âœ— ä¸»README.md åˆ›å»ºå¤±è´¥: {str(e)}")
    
    def install_dependencies(self):
        """
        å®‰è£…é¡¹ç›®ä¾èµ–
        """
        print("ğŸ“¦ æ­£åœ¨å®‰è£…é¡¹ç›®ä¾èµ–...")
        
        dependencies = [
            'numpy',
            'pandas', 
            'matplotlib',
            'seaborn',
            'scikit-learn',
            'plotly',
            'scipy'
        ]
        
        for dep in dependencies:
            print(f"å®‰è£… {dep}...")
            # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…å®‰è£…éœ€è¦åœ¨å‘½ä»¤è¡Œæ‰§è¡Œ
        
        print("ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
        print(f"python -m pip install {' '.join(dependencies)}")
    
    def show_project_status(self):
        """
        æ˜¾ç¤ºé¡¹ç›®çŠ¶æ€
        """
        print("\nğŸ“Š é¡¹ç›®çŠ¶æ€æ¦‚è§ˆ")
        print("=" * 50)
        
        for problem in self.problems:
            problem_path = os.path.join(self.project_root, problem)
            if os.path.exists(problem_path):
                code_path = os.path.join(problem_path, "ä»£ç ")
                result_path = os.path.join(problem_path, "å¯è§†åŒ–ç»“æœ")
                
                code_files = len([f for f in os.listdir(code_path) 
                                if f.endswith('.py')]) if os.path.exists(code_path) else 0
                result_files = len(os.listdir(result_path)) if os.path.exists(result_path) else 0
                
                print(f"ğŸ“ {problem}:")
                print(f"   ä»£ç æ–‡ä»¶: {code_files} ä¸ª")
                print(f"   ç»“æœæ–‡ä»¶: {result_files} ä¸ª")
                print(f"   çŠ¶æ€: {'âœ“ å·²åˆ›å»º' if code_files > 0 else 'âš ï¸ å¾…å¼€å‘'}")
            else:
                print(f"âŒ {problem}: æ–‡ä»¶å¤¹ä¸å­˜åœ¨")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸ¯ æ•°å­¦å»ºæ¨¡é¡¹ç›®ç®¡ç†å™¨")
    print("=" * 40)
    
    manager = MathModelingProjectManager()
    
    print("\n1. åˆ›å»ºä»£ç æ¨¡æ¿...")
    manager.create_problem_templates()
    
    print("\n2. åˆ›å»ºREADMEæ–‡ä»¶...")
    manager.create_readme_files()
    manager.create_main_readme()
    
    print("\n3. æ˜¾ç¤ºé¡¹ç›®çŠ¶æ€...")
    manager.show_project_status()
    
    print("\n4. ä¾èµ–å®‰è£…æç¤º...")
    manager.install_dependencies()
    
    print("\nğŸ‰ é¡¹ç›®åˆå§‹åŒ–å®Œæˆï¼")
    print("\nğŸ“‹ æ¥ä¸‹æ¥çš„æ­¥éª¤:")
    print("1. å°†æ¯”èµ›é¢˜ç›®Wordæ–‡æ¡£æ”¾å…¥é¡¹ç›®æ ¹ç›®å½•")
    print("2. è¿è¡Œ 'python é¢˜ç›®åˆ†æå™¨.py' åˆ†æé¢˜ç›®")
    print("3. æ ¹æ®åˆ†æç»“æœå¼€å§‹åœ¨å„é—®é¢˜æ–‡ä»¶å¤¹ä¸­ç¼–ç ")
    print("4. ä½¿ç”¨å¯è§†åŒ–æ¨¡å—ç”Ÿæˆå›¾è¡¨å’Œç»“æœ")

if __name__ == "__main__":
    main()