#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é—®é¢˜1 - æ•°æ®åˆ†ææ¨¡å—
ç”¨äºæ•°æ®æ¢ç´¢æ€§åˆ†æå’Œç»Ÿè®¡æè¿°

åˆ›å»ºæ—¶é—´: 2025-07-25 21:37:58
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class DataAnalyzer:
    """
    æ•°æ®åˆ†æå™¨
    """
    
    def __init__(self, data):
        self.data = data
        self.analysis_results = {}
    
    def basic_info(self):
        """
        åŸºæœ¬ä¿¡æ¯åˆ†æ
        """
        print("ğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯")
        print("=" * 30)
        print(f"æ•°æ®å½¢çŠ¶: {self.data.shape}")
        print(f"æ•°æ®ç±»å‹:
{self.data.dtypes}")
        print(f"
ç¼ºå¤±å€¼ç»Ÿè®¡:
{self.data.isnull().sum()}")
        
        # æ•°å€¼å‹å˜é‡æè¿°æ€§ç»Ÿè®¡
        numeric_data = self.data.select_dtypes(include=[np.number])
        if not numeric_data.empty:
            print(f"
ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡:")
            print(numeric_data.describe())
    
    def correlation_analysis(self):
        """
        ç›¸å…³æ€§åˆ†æ
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        if numeric_data.shape[1] < 2:
            print("æ•°å€¼å‹å˜é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§åˆ†æ")
            return
        
        # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
        corr_matrix = numeric_data.corr()
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5)
        plt.title(f'é—®é¢˜1 - å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾')
        plt.tight_layout()
        plt.savefig(f'../å¯è§†åŒ–ç»“æœ/é—®é¢˜1_ç›¸å…³æ€§åˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return corr_matrix
    
    def distribution_analysis(self):
        """
        åˆ†å¸ƒåˆ†æ
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        
        if numeric_data.empty:
            print("æ²¡æœ‰æ•°å€¼å‹å˜é‡å¯åˆ†æ")
            return
        
        n_cols = min(3, len(numeric_data.columns))
        n_rows = (len(numeric_data.columns) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
        if n_rows == 1:
            axes = [axes] if n_cols == 1 else axes
        else:
            axes = axes.flatten()
        
        for i, col in enumerate(numeric_data.columns):
            if i < len(axes):
                # ç›´æ–¹å›¾
                axes[i].hist(numeric_data[col], bins=30, alpha=0.7, edgecolor='black')
                axes[i].set_title(f'{col} åˆ†å¸ƒ')
                axes[i].set_xlabel(col)
                axes[i].set_ylabel('é¢‘æ•°')
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                mean_val = numeric_data[col].mean()
                std_val = numeric_data[col].std()
                axes[i].axvline(mean_val, color='red', linestyle='--', 
                              label=f'å‡å€¼: {mean_val:.2f}')
                axes[i].legend()
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(numeric_data.columns), len(axes)):
            axes[i].set_visible(False)
        
        plt.suptitle(f'é—®é¢˜1 - å˜é‡åˆ†å¸ƒåˆ†æ')
        plt.tight_layout()
        plt.savefig(f'../å¯è§†åŒ–ç»“æœ/é—®é¢˜1_åˆ†å¸ƒåˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def outlier_detection(self):
        """
        å¼‚å¸¸å€¼æ£€æµ‹
        """
        numeric_data = self.data.select_dtypes(include=[np.number])
        
        if numeric_data.empty:
            return
        
        outliers_info = {}
        
        for col in numeric_data.columns:
            Q1 = numeric_data[col].quantile(0.25)
            Q3 = numeric_data[col].quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = numeric_data[(numeric_data[col] < lower_bound) | 
                                  (numeric_data[col] > upper_bound)][col]
            
            outliers_info[col] = {
                'count': len(outliers),
                'percentage': len(outliers) / len(numeric_data) * 100,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound
            }
        
        # ç»˜åˆ¶ç®±çº¿å›¾
        plt.figure(figsize=(12, 6))
        numeric_data.boxplot()
        plt.title(f'é—®é¢˜1 - å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆç®±çº¿å›¾ï¼‰')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(f'../å¯è§†åŒ–ç»“æœ/é—®é¢˜1_å¼‚å¸¸å€¼æ£€æµ‹.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return outliers_info

def main():
    """
    æ•°æ®åˆ†æä¸»å‡½æ•°
    """
    print(f"ğŸ“Š é—®é¢˜1 æ•°æ®åˆ†ææ¨¡å—")
    print("=" * 40)
    
    # è¿™é‡Œéœ€è¦åŠ è½½æ•°æ®
    # data = pd.read_csv('your_data.csv')  # æ›¿æ¢ä¸ºå®é™…æ•°æ®è·¯å¾„
    
    # ç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    data = pd.DataFrame({
        'feature1': np.random.normal(100, 15, 1000),
        'feature2': np.random.exponential(2, 1000),
        'feature3': np.random.uniform(0, 100, 1000),
        'target': np.random.normal(50, 10, 1000)
    })
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DataAnalyzer(data)
    
    # æ‰§è¡Œåˆ†æ
    analyzer.basic_info()
    print("
" + "="*50 + "
")
    
    corr_matrix = analyzer.correlation_analysis()
    print("
" + "="*50 + "
")
    
    analyzer.distribution_analysis()
    print("
" + "="*50 + "
")
    
    outliers_info = analyzer.outlier_detection()
    
    print("
ğŸ‰ æ•°æ®åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
